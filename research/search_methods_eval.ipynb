{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9d9930ae-702c-4edf-bedb-01af0e82ac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# метрики: hits@1, hits@5, ndcg@5, hits@10, ndcg@10, ndcg@20 (5 результатов на первой странице)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13fd8625-8087-4b8f-b4b1-e21c48d28277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pypdf import PdfReader\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe59c3ae-7509-48d9-b41c-1f8df9f518a8",
   "metadata": {},
   "source": [
    "# getting data ready"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdc3b16-4190-4998-86b5-075499f8bcf4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fd3254c-c799-4a6c-be3a-e23bc8923e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('files_cropped/res_dict_10.pickle', 'rb') as file:\n",
    "    gd = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9e723a6-a19a-4f0d-9869-38d42ab551f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = []\n",
    "i = 0\n",
    "for main_name, main_section in gd.items():\n",
    "    for section_name, section_docs in main_section.items():\n",
    "        for doc in section_docs:\n",
    "            if 'file_markdown' in doc:\n",
    "                del doc['file_markdown']\n",
    "            doc['OKS_main'] = main_name\n",
    "            doc['OKS_section'] = section_name\n",
    "            doc['id'] = i\n",
    "            i += 1\n",
    "            all_docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "578c78d1-73f6-49b8-aba7-023f5cbcb774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['number', 'title', 'status', 'date_start', 'date_cancel', 'replaced_by', 'OKS', 'file_path', 'file_url', 'OKS_main', 'OKS_section', 'id'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_docs[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94b6f509-15be-407a-abf3-83d32d522355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3519, 3519)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique([doc['number'] for doc in all_docs])), len(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd0a0492-c459-4d28-9e9f-d761cf289cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('files_cropped/docs_flattened.pickle', 'wb') as file:\n",
    "    pickle.dump(all_docs, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2d9449f8-d3bb-4d93-a7b3-cb06c5ceb1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/documents_info.pickle', 'wb') as file:\n",
    "    pickle.dump(all_docs, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97da5bba-3a96-4441-8764-5974d8c9cfa8",
   "metadata": {},
   "source": [
    "## queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ebb39549-529b-4e67-a5f1-912dd6e8c892",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_dataset.pickle', 'rb') as file:\n",
    "    queries = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8719cbc5-b29e-4ee5-bdf9-648d1607a16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_queries = []\n",
    "for filename, doc_queries in queries.items():\n",
    "    new_q = {}\n",
    "    doc = [doc for doc in all_docs if doc['file_path'] == filename][0]\n",
    "    new_q['doc_id'] = doc['id']\n",
    "    new_q['filename'] = doc['file_path']\n",
    "    new_q['doc_gost_number'] = doc['number']\n",
    "    new_q['doc_title'] = doc['title']\n",
    "    new_q['queries'] = doc_queries\n",
    "    new_queries.append(deepcopy(new_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1216d850-4ba8-4f8c-9904-c4aa33f4aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_dataset_final.pickle', 'wb') as file:\n",
    "    pickle.dump(new_queries, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a8e05e5b-45e9-4282-9fd2-159d29ff838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/queries.pickle', 'wb') as file:\n",
    "    pickle.dump(new_queries, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0907a275-9874-4837-8fad-c20fc7c005ae",
   "metadata": {},
   "source": [
    "# Texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17424210-23bd-48c4-a605-13a7176b1dc5",
   "metadata": {},
   "source": [
    "## litle preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c7397fe-77b1-4a87-a609-6e984597202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_folder = 'files_cropped/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f393517-959c-412c-aafa-cfa9882bd4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c6fdc64979343d0aaa8a55d5eaa5ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def process_doc(doc):\n",
    "    text = ''\n",
    "    print('1')\n",
    "    if doc['file_path']:\n",
    "        try:\n",
    "            reader = PdfReader(doc_folder + doc['file_path'])\n",
    "            for page in reader.pages[1:-1]:\n",
    "                page_text = page.extract_text()\n",
    "                text += (page_text + '\\n')\n",
    "        except:\n",
    "            pass\n",
    "    doc['text'] = doc['title'] + '\\n\\n' + text\n",
    "    return doc\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Parallel(n_jobs=-1) as parallel:\n",
    "        all_docs = parallel(delayed(process_doc)(doc) for doc in tqdm(all_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ef49269-c4e0-431e-a23c-09371f634fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['number', 'title', 'status', 'date_start', 'date_cancel', 'replaced_by', 'OKS', 'file_path', 'file_url', 'OKS_main', 'OKS_section', 'id'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_docs[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc642e1-6de3-43be-b90f-8742617eae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_docs)):\n",
    "    all_docs[i]['text'] = all_docs[i]['text'].replace('\\xad\\n', '').replace('\\n\\xad', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "72e861c1-f90c-4504-a607-8e78e31383dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/docs_with_text.pickle', 'wb') as f:\n",
    "    pickle.dump(all_docs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0a08f268-2cf5-43a1-afdb-1d8f80dca471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_doc(doc):\n",
    "    text = doc['text']\n",
    "    text = text.lower()\n",
    "    words = [w.strip(punct) for w in word_tokenize(text)]\n",
    "    words = ' '.join([w for w in words if w not in stopwords and w != ''])\n",
    "    text = ''.join(lemmatizer.lemmatize(words))\n",
    "    doc['text'] = text\n",
    "    return doc\n",
    "def stem_doc(doc):\n",
    "    text = doc['text']\n",
    "    text = text.lower()\n",
    "    words = [w.strip(punct) for w in word_tokenize(text)]\n",
    "    text = ' '.join([stemmer.stem(w) for w in words if w not in stopwords and w != ''])\n",
    "    doc['text'] = text\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e3f8a8d0-fc46-40dd-90ba-45aa1c8e2632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a47a3fb629a94bf4b6f2050f0963a448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Parallel(n_jobs=-1) as parallel:\n",
    "        docs_lemmatized = parallel(delayed(lemmatize_doc)(doc) for doc in tqdm(all_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "30b0d9fd-3f44-4b98-8c3e-f62aa75c1f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/lemmatized_docs.pickle', 'wb') as f:\n",
    "    pickle.dump(docs_lemmatized, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce733032-ca2d-4d89-81b6-36d76db8eee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0d1f50cd124bd78963c64849f14af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    with Parallel(n_jobs=-1) as parallel:\n",
    "        docs_stemmed = parallel(delayed(stem_doc)(doc) for doc in tqdm(all_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "287ecb3e-cd96-47f5-b64f-d6af39545042",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/stemmed_docs.pickle', 'wb') as f:\n",
    "    pickle.dump(docs_stemmed, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a28207f-b880-4c12-8584-7a5e4634c48c",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "221844c8-b5c2-4192-a776-787559bf9000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from pymystem3 import Mystem\n",
    "from nltk.tokenize import word_tokenize\n",
    "from langchain_community.retrievers import BM25Retriever, TFIDFRetriever\n",
    "from langchain_core.documents import Document\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2e50c64-3920-4cf6-bbf5-4237d361c7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_results(results, precision=2):\n",
    "    for name, metrics in results.items():\n",
    "        print(f\"{(' '.join(name.split('_'))).capitalize()}:\")\n",
    "        for metric_name, metric_value in metrics.items():\n",
    "            if 'hits' in metric_name or 'dcg' in metric_name:\n",
    "               print(f\"{metric_name.upper().replace('_', '@')}: {round(metric_value, precision)}\")\n",
    "            elif metric_name == 'time_per_query':\n",
    "                print(f\"Average time per query: {round(metric_value*1000, 1)}ms\")\n",
    "            elif metric_name == 'not_found_queries':\n",
    "                print(f\"Number of not found queries: {len(metric_value)}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1bb8bcd-dcf8-48e3-bdba-8954da3be030",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('russian')\n",
    "stemmer = SnowballStemmer('russian')\n",
    "punct = '!\"#$%&()*\\+,-\\./:;<=>?@\\[\\]^_`{|}~„“«»†*\\—/\\-‘’'\n",
    "lemmatizer = Mystem(grammar_info=False)\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08ab8648-e465-46ba-ab58-7ad4f397d6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/queries.pickle', 'rb') as f:\n",
    "    queries = pickle.load(f)\n",
    "with open('dataset/docs_with_text.pickle', 'rb') as f:\n",
    "    all_docs = pickle.load(f)\n",
    "with open('dataset/results.pickle', 'rb') as f:\n",
    "    results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26354859-6551-481e-b712-dbcacddc44de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hits_k(requested_doc_id: int, found_doc_idx: list, ks: list):\n",
    "    hits = []\n",
    "    for k in ks:\n",
    "        cur_res = 0\n",
    "        if requested_doc_id in found_doc_idx[:k]:\n",
    "            cur_res = 1\n",
    "        hits.append((k, cur_res))\n",
    "    return hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6318186-782e-45a5-8830-5153a91a4d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_k(requested_doc_id: int, found_doc_idx: list, ks: list):\n",
    "    dcgs = []\n",
    "    requested_doc_pos = [i for i, doc_id in enumerate(found_doc_idx) if doc_id == requested_doc_id]\n",
    "    if not requested_doc_pos:\n",
    "        return [(k, 0) for k in ks]\n",
    "    # if len(requested_doc_pos) > 1:\n",
    "    #     raise ValueError(\"Seems like duplicate document ids are encountered\")\n",
    "    requested_doc_pos = requested_doc_pos[0] + 1\n",
    "    for k in ks:\n",
    "        dcg = (1 / np.log2(1 + requested_doc_pos)) * (requested_doc_pos <= k)\n",
    "        dcgs.append((k, dcg))\n",
    "    return dcgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd480e19-e7df-46bd-bbc8-68aa59fcb90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_retriever_pipeline(\n",
    "    retriever,\n",
    "    queries: list,\n",
    "    hits_ks: list,\n",
    "    dcg_ks: list,\n",
    "    not_found_queries_threshold: int = 20,\n",
    "    progress_bar: bool = True,\n",
    "    query_preproc_fn = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        retriever: LangChain retriever\n",
    "        queries: search queries in following format: [{'doc_id': 123, 'queries': ['query1', 'query2', ...], ...}, ...]\n",
    "        hits_ks: for wich Ks compute Hits@K in format of list: [1, 2, 3]\n",
    "        dcg_ks: for which Ks compute DCG@K in format of list: [1, 2, 3]\n",
    "        not_found_queries_threshold: return also queries that are not in top k documents (or None not to return them at all)\n",
    "        progress_bar: whether to enable progress bar\n",
    "        query_preproc_fn: function that preprocesses query\n",
    "    Returns:\n",
    "        dict: metrics in following format: {'hits_1': 0, 'hits_2': 0, ...}\n",
    "    \"\"\"\n",
    "    metrics = dict()\n",
    "    not_found_queries = []\n",
    "    for k in hits_ks:\n",
    "        metrics[f\"hits_{k}\"] = 0\n",
    "    for k in dcg_ks:\n",
    "        metrics[f\"dcg_{k}\"] = 0\n",
    "    query_counter = 0\n",
    "    t = time.time()\n",
    "    for query in tqdm(queries, desc='Scoring queries', disable=not progress_bar):\n",
    "        requested_doc_id = query['doc_id']\n",
    "        for subquery in query['queries']:\n",
    "            query_counter += 1\n",
    "            subquery_text = subquery\n",
    "            if query_preproc_fn:\n",
    "                subquery_text = query_preproc_fn(subquery)\n",
    "            found_doc_idx = [res.metadata['doc_id'] for res in retriever.invoke(subquery_text)]\n",
    "            subquery_hits = hits_k(requested_doc_id, found_doc_idx, hits_ks)\n",
    "            subquery_dcgs = dcg_k(requested_doc_id, found_doc_idx, dcg_ks)\n",
    "            if not_found_queries_threshold and requested_doc_id not in found_doc_idx[:not_found_queries_threshold]:\n",
    "                not_found_queries.append({'doc_id': requested_doc_id, 'doc_title': query['doc_title'], 'query': subquery})\n",
    "            for k, score in subquery_hits:\n",
    "                metrics[f\"hits_{k}\"] += score\n",
    "            for k, score in subquery_dcgs:\n",
    "                metrics[f\"dcg_{k}\"] += score\n",
    "    metrics['time_per_query'] = time.time() - t\n",
    "    for metric_name, metric_value in metrics.items():\n",
    "        metrics[metric_name] = metric_value / query_counter\n",
    "    metrics['not_found_queries'] = not_found_queries\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc4c518b-946e-4f28-86d2-f277e3bc002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_query(text):\n",
    "    text = text.lower()\n",
    "    words = [w.strip(punct) for w in word_tokenize(text)]\n",
    "    words = ' '.join([w for w in words if w not in stopwords and w != ''])\n",
    "    text = ''.join(lemmatizer.lemmatize(words))\n",
    "    return text\n",
    "def lemmatize_query2(text):\n",
    "    text = text.lower()\n",
    "    words = [w.strip(punct) for w in word_tokenize(text)]\n",
    "    words = [w for w in words if w not in stopwords and w != '']\n",
    "    text = ' '.join([morph.parse(w)[0].normal_form for w in words])\n",
    "    return text\n",
    "def stem_query(text):\n",
    "    text = text.lower()\n",
    "    words = [w.strip(punct) for w in word_tokenize(text)]\n",
    "    text = ' '.join([stemmer.stem(w) for w in words if w not in stopwords and w != ''])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49be6f0-b63a-433d-84a8-594042612c61",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f028cd4d-7d41-456e-bf00-0b95cd83f139",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = BM25Retriever.from_documents(\n",
    "    [Document(page_content=doc['text'], metadata={'doc_id': doc['id'], 'title': doc['title']}) for doc in all_docs],\n",
    "    k=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "114c765c-ebe3-4da1-9a29-020f739fa6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffdc1d3df4244024af3311feb318f37b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scoring queries:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results['bm25_clear'] = test_retriever_pipeline(\n",
    "    retriever=retriever,\n",
    "    queries=queries,\n",
    "    hits_ks=[1, 5, 10],\n",
    "    dcg_ks=[5, 10, 20],\n",
    "    not_found_queries_threshold=20,\n",
    "    progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "792c1a36-81c1-43b3-b3b5-29b902395608",
   "metadata": {},
   "outputs": [],
   "source": [
    "del retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8e8ff50-0253-4d22-8ffe-6340b7284cb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bm25_stemmed = BM25Retriever.from_documents(\n",
    "    [Document(page_content=doc['text'], metadata={'doc_id': doc['id'], 'title': doc['title']}) for doc in docs_stemmed],\n",
    "    k=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b68bd04-4332-422b-96b9-b36c10652dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa62f8768e684d10b8bb10111fbb93a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scoring queries:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results['bm25_stemmed'] = test_retriever_pipeline(\n",
    "    retriever=bm25_stemmed,\n",
    "    queries=queries,\n",
    "    hits_ks=[1, 5, 10],\n",
    "    dcg_ks=[5, 10, 20],\n",
    "    not_found_queries_threshold=20,\n",
    "    progress_bar=True,\n",
    "    query_preproc_fn=stem_query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8608a857-48f7-4f04-ba8d-f90178beb907",
   "metadata": {},
   "outputs": [],
   "source": [
    "del bm25_stemmed, docs_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5e7bc2f2-42ec-49ab-a82a-2640281a1ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_lemmatized = BM25Retriever.from_documents(\n",
    "    [Document(page_content=doc['text'], metadata={'doc_id': doc['id'], 'title': doc['title']}) for doc in docs_lemmatized],\n",
    "    k=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d2429b4f-987a-46fa-a9ad-a91cd2d5b23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02572f30e1f24a29ad628ae424b77ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scoring queries:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results['bm25_lemmatized'] = test_retriever_pipeline(\n",
    "    retriever=bm25_lemmatized,\n",
    "    queries=queries,\n",
    "    hits_ks=[1, 5, 10],\n",
    "    dcg_ks=[5, 10, 20],\n",
    "    not_found_queries_threshold=20,\n",
    "    progress_bar=True,\n",
    "    query_preproc_fn=lemmatize_query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "22c67fdd-ed90-428b-b9c0-4047dde8464a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bm25 clear:\n",
      "HITS@1: 0.395\n",
      "HITS@5: 0.655\n",
      "HITS@10: 0.72\n",
      "DCG@5: 0.52954\n",
      "DCG@10: 0.55046\n",
      "DCG@20: 0.57054\n",
      "Average time per query: 0.01036s\n",
      "Number of not found queries: 40\n",
      "\n",
      "Bm25 stemmed:\n",
      "HITS@1: 0.56\n",
      "HITS@5: 0.83\n",
      "HITS@10: 0.895\n",
      "DCG@5: 0.70912\n",
      "DCG@10: 0.73019\n",
      "DCG@20: 0.74035\n",
      "Average time per query: 0.00997s\n",
      "Number of not found queries: 13\n",
      "\n",
      "Bm25 lemmatized:\n",
      "HITS@1: 0.57\n",
      "HITS@5: 0.82\n",
      "HITS@10: 0.9\n",
      "DCG@5: 0.70672\n",
      "DCG@10: 0.73225\n",
      "DCG@20: 0.74098\n",
      "Average time per query: 1.95256s\n",
      "Number of not found queries: 13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretty_print_results(results, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf8833b-853a-46dd-8346-69b576019b2f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c95aa34-e300-41f9-a369-d87966a79e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/lemmatized_docs.pickle', 'rb') as f:\n",
    "    docs_lemmatized = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ceef5d4-e712-4e4e-9e02-5f4bb4956400",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_lemmatized = TFIDFRetriever.from_documents(\n",
    "    [Document(page_content=doc['text'], metadata={'doc_id': doc['id'], 'title': doc['title']}) for doc in docs_lemmatized],\n",
    "    k=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78d166b7-7fb7-49af-b2d4-9f7a3e19ac5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e44bc136ed564557bb10d2ae11e97801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scoring queries:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results['tfidf_lemmatized'] = test_retriever_pipeline(\n",
    "    retriever=tfidf_lemmatized,\n",
    "    queries=queries,\n",
    "    hits_ks=[1, 5, 10],\n",
    "    dcg_ks=[5, 10, 20],\n",
    "    not_found_queries_threshold=20,\n",
    "    progress_bar=True,\n",
    "    query_preproc_fn=lemmatize_query2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02832f2b-9891-42de-b645-22f71e16d845",
   "metadata": {},
   "outputs": [],
   "source": [
    "del docs_lemmatized, tfidf_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd77a661-dce3-4f87-8d2c-ef1c133403a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_clear = TFIDFRetriever.from_documents(\n",
    "    [Document(page_content=doc['text'], metadata={'doc_id': doc['id'], 'title': doc['title']}) for doc in all_docs],\n",
    "    k=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed7d4ce6-8cef-4bb2-a193-43f64be0800c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68b11f1819fb416495f00c586765595a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scoring queries:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results['tfidf_clear'] = test_retriever_pipeline(\n",
    "    retriever=tfidf_clear,\n",
    "    queries=queries,\n",
    "    hits_ks=[1, 5, 10],\n",
    "    dcg_ks=[5, 10, 20],\n",
    "    not_found_queries_threshold=20,\n",
    "    progress_bar=True,\n",
    "    query_preproc_fn=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdf177fa-c3d7-4f40-ad50-a2916eab1cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tfidf_clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ceb84cb4-289a-43cb-bf6b-4646e3ca9588",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/stemmed_docs.pickle', 'rb') as f:\n",
    "    docs_stemmed = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0173d667-5f76-4bce-9ff1-96654d01721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_stemmed = TFIDFRetriever.from_documents(\n",
    "    [Document(page_content=doc['text'], metadata={'doc_id': doc['id'], 'title': doc['title']}) for doc in docs_stemmed],\n",
    "    k=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86c9f871-9673-4ae3-a277-42b96f904bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1a7595ea07446387cfd10ba362b15c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scoring queries:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results['tfidf_stemmed'] = test_retriever_pipeline(\n",
    "    retriever=tfidf_stemmed,\n",
    "    queries=queries,\n",
    "    hits_ks=[1, 5, 10],\n",
    "    dcg_ks=[5, 10, 20],\n",
    "    not_found_queries_threshold=20,\n",
    "    progress_bar=True,\n",
    "    query_preproc_fn=stem_query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0b672a7-033f-4471-9581-1d42c20788aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "del docs_stemmed, tfidf_stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bead67-be13-494f-ae36-6ec1c058eea2",
   "metadata": {},
   "source": [
    "## embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23506349-08f7-4858-83a3-b812bb7b2386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain.retrievers import EnsembleRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bca760fc-e5db-46fe-ad5e-9ea8ddaf5a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/splitted_texts_query.pickle', 'rb') as f:\n",
    "    embedded_chunks = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f54d413-fcba-4082-bb55-4602759338e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_documents_from_chunks(ranked_chunks):\n",
    "    ranked_docs = dict()\n",
    "    for doc_id, doc_score in ranked_chunks:\n",
    "        if not doc_id in ranked_docs:\n",
    "            ranked_docs[doc_id] = (doc_score, 1)\n",
    "        else:\n",
    "            past_score, past_number = ranked_docs[doc_id]\n",
    "            ranked_docs[doc_id] = (past_score + doc_score, past_number + 1)\n",
    "    for doc_id, (overall_doc_score, hitted_chunk_number) in ranked_docs.items():\n",
    "        ranked_docs[doc_id] = overall_doc_score / hitted_chunk_number\n",
    "    ranked_docs = sorted(ranked_docs, key=ranked_docs.get, reverse=False)\n",
    "    return ranked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1824fb7-ccf4-464a-8fec-d22af0e3679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_vectorstore_pipeline(\n",
    "    vectorstore,\n",
    "    queries: list,\n",
    "    hits_ks: list,\n",
    "    dcg_ks: list,\n",
    "    not_found_queries_threshold: int = 20,\n",
    "    progress_bar: bool = True,\n",
    "    query_preproc_fn = None,\n",
    "    doc_id_str = \"doc_id\",\n",
    "    chunk_search=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        vectorstore: LangChain vectorstore\n",
    "        queries: search queries in following format: [{'doc_id': 123, 'queries': ['query1', 'query2', ...], ...}, ...]\n",
    "        hits_ks: for wich Ks compute Hits@K in format of list: [1, 2, 3]\n",
    "        dcg_ks: for which Ks compute DCG@K in format of list: [1, 2, 3]\n",
    "        not_found_queries_threshold: return also queries that are not in top k documents (or None not to return them at all)\n",
    "        progress_bar: whether to enable progress bar\n",
    "        query_preproc_fn: function that preprocesses query\n",
    "    Returns:\n",
    "        dict: metrics in following format: {'hits_1': 0, 'hits_2': 0, ...}\n",
    "    \"\"\"\n",
    "    metrics = dict()\n",
    "    not_found_queries = []\n",
    "    for k in hits_ks:\n",
    "        metrics[f\"hits_{k}\"] = 0\n",
    "    for k in dcg_ks:\n",
    "        metrics[f\"dcg_{k}\"] = 0\n",
    "    query_counter = 0\n",
    "    t = time.time()\n",
    "    for query in tqdm(queries, desc='Scoring queries', disable=not progress_bar):\n",
    "        requested_doc_id = query['doc_id']\n",
    "        for subquery in query['queries']:\n",
    "            query_counter += 1\n",
    "            subquery_text = subquery\n",
    "            if query_preproc_fn:\n",
    "                subquery_text = query_preproc_fn(subquery)\n",
    "            if not chunk_search:\n",
    "                found_doc_idx = [res[0].metadata[doc_id_str] for res in vectorstore.similarity_search_with_relevance_scores(subquery_text, k=20)]\n",
    "            else:\n",
    "                ranked_chunks = [\n",
    "                    (res[0].metadata[doc_id_str], res[1]) \n",
    "                    for res in vectorstore.similarity_search_with_score(subquery_text, k=1000)\n",
    "                ]\n",
    "                found_doc_idx = rank_documents_from_chunks(ranked_chunks)\n",
    "            subquery_hits = hits_k(requested_doc_id, found_doc_idx, hits_ks)\n",
    "            subquery_dcgs = dcg_k(requested_doc_id, found_doc_idx, dcg_ks)\n",
    "            if not_found_queries_threshold and requested_doc_id not in found_doc_idx[:not_found_queries_threshold]:\n",
    "                not_found_queries.append({'doc_id': requested_doc_id, 'doc_title': query['doc_title'], 'query': subquery})\n",
    "            for k, score in subquery_hits:\n",
    "                metrics[f\"hits_{k}\"] += score\n",
    "            for k, score in subquery_dcgs:\n",
    "                metrics[f\"dcg_{k}\"] += score\n",
    "    metrics['time_per_query'] = time.time() - t\n",
    "    for metric_name, metric_value in metrics.items():\n",
    "        metrics[metric_name] = metric_value / query_counter\n",
    "    metrics['not_found_queries'] = not_found_queries\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94f56a64-0c79-4253-85e8-907f7cba1651",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0d939a011a45bb9d47515870027f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1645286\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\1645286\\.cache\\huggingface\\hub\\models--intfloat--multilingual-e5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b547ae9ffda4d94bc9d17b280099fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/160k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d3ff4e9da34cd190126adcf43fc2f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2614b6b54698466dbc1b508bacf7132f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/655 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161651aeba384ac09c2da269b1e5d12f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b263e4ab91464b95025482327f236e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ce7d59ace949ea99f75258cd25424b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f588ce40d94a9295b5d6896183fbe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580f31e37fa4408c97d3eadee708f159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994ccfe18b634c2d90537d8613eacb02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"intfloat/multilingual-e5-small\" # large\n",
    "model_kwargs = {'device': 'cuda'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b36e159-b35a-4269-90ef-ad78ed673926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99305e522e945e6af52642949a7798f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(all_docs):\n",
    "    text = f\"query: {doc['title']}\"\n",
    "    doc['embedding_title'] = deepcopy(hf.embed_query(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1a2c01ee-3f3b-4329-b3a7-b2ab38bfdff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/all_docs_with_title_embeddings.pickle', 'wb') as f:\n",
    "    pickle.dump(all_docs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5cfbf8c-b1dc-4646-810b-4829853982dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_vectorstore = FAISS.from_embeddings(\n",
    "    [(chunk.page_content, chunk.metadata['embedding']) for chunk in embedded_chunks],\n",
    "    hf,\n",
    "    metadatas=[\n",
    "        {\n",
    "            'doc_id': chunk.metadata['doc_id'],\n",
    "            'title': chunk.metadata['title']\n",
    "        }\n",
    "        for chunk in embedded_chunks\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69c2af3b-ce85-4754-b5b6-8a50b9fefdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_vectorstore_titles = FAISS.from_embeddings(\n",
    "    [(doc['title'], doc['embedding_title']) for doc in all_docs],\n",
    "    hf,\n",
    "    metadatas=[\n",
    "        {\n",
    "            'doc_id': doc['id']\n",
    "        }\n",
    "        for doc in all_docs\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7244a8a1-147e-49b8-a88d-dba83c273f78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82315f0b78204786aa3f63909e939807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scoring queries:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hits_1': 0.565,\n",
       " 'hits_5': 0.875,\n",
       " 'hits_10': 0.94,\n",
       " 'dcg_5': 0.7386086454133057,\n",
       " 'dcg_10': 0.7594829837499144,\n",
       " 'dcg_20': 0.7660488660743507,\n",
       " 'time_per_query': 0.04973018288612366,\n",
       " 'not_found_queries': [{'doc_id': 2211,\n",
       "   'doc_title': 'Тара транспортная наполненная. Метод испытания в водяных брызгах',\n",
       "   'query': 'защита товара от дождя гост'},\n",
       "  {'doc_id': 1369,\n",
       "   'doc_title': 'Транзисторы биполярные. Метод измерения постоянной времени цепи обратной связи на высокой частоте',\n",
       "   'query': 'методы тестирования транзисторов с точностью'},\n",
       "  {'doc_id': 1918,\n",
       "   'doc_title': 'Болты клеммные для рельсовых скреплений железнодорожного пути. Технические условия',\n",
       "   'query': 'болты клеммные для рельсовых скреплений железнодорожного пути технические условия'},\n",
       "  {'doc_id': 817,\n",
       "   'doc_title': 'Цепи тяговые вильчатые. Технические условия',\n",
       "   'query': 'технические условия цепей'},\n",
       "  {'doc_id': 1050,\n",
       "   'doc_title': 'Котлы отопительные водогрейные теплопроизводительностью до 100 кВт. Общие технические условия',\n",
       "   'query': 'технические условия для котлов'},\n",
       "  {'doc_id': 2601,\n",
       "   'doc_title': 'Реактивы. Ацетилацетон. Технические условия',\n",
       "   'query': 'ацетилацетон технические условия'},\n",
       "  {'doc_id': 973,\n",
       "   'doc_title': 'Стамески плоские и полукруглые. Технические условия',\n",
       "   'query': 'технические условия на стамески'}]}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectorstore_pipeline( # e5-large chunk search (doc_score = mean embedding score)\n",
    "    faiss_vectorstore,\n",
    "    queries,\n",
    "    hits_ks=[1, 5, 10],\n",
    "    dcg_ks=[5, 10, 20],\n",
    "    not_found_queries_threshold=20,\n",
    "    progress_bar=True,\n",
    "    query_preproc_fn=lambda query: f\"query: {query}\",\n",
    "    chunk_search=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21cc714e-2e56-47d3-bae2-0ffa653fcf48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a05a4266f44612a30dda41e8e6f6bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scoring queries:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hits_1': 0.765,\n",
       " 'hits_5': 0.935,\n",
       " 'hits_10': 0.955,\n",
       " 'dcg_5': 0.8585697951412524,\n",
       " 'dcg_10': 0.8649134284312257,\n",
       " 'dcg_20': 0.8701623767662581,\n",
       " 'time_per_query': 0.017327221632003783,\n",
       " 'not_found_queries': [{'doc_id': 1258,\n",
       "   'doc_title': 'Аппараты пускорегулирующие для разрядных ламп. Общие технические требования',\n",
       "   'query': 'тест-таблицы для факсимильных аппаратов'},\n",
       "  {'doc_id': 2211,\n",
       "   'doc_title': 'Тара транспортная наполненная. Метод испытания в водяных брызгах',\n",
       "   'query': 'защита товара от дождя гост'},\n",
       "  {'doc_id': 1369,\n",
       "   'doc_title': 'Транзисторы биполярные. Метод измерения постоянной времени цепи обратной связи на высокой частоте',\n",
       "   'query': 'методы тестирования транзисторов с точностью'},\n",
       "  {'doc_id': 2263,\n",
       "   'doc_title': 'Материалы ворсовые. Метод определения несминаемости ворса',\n",
       "   'query': 'материалы искусственные мехов проверка'},\n",
       "  {'doc_id': 2253,\n",
       "   'doc_title': 'Волокно и жгут химические. Методы определения разрывной нагрузки и удлинение при разрыве',\n",
       "   'query': 'испытание волокна на растяжение'}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectorstore_pipeline( # e5-small\n",
    "    faiss_vectorstore_titles,\n",
    "    queries,\n",
    "    hits_ks=[1, 5, 10],\n",
    "    dcg_ks=[5, 10, 20],\n",
    "    not_found_queries_threshold=20,\n",
    "    progress_bar=True,\n",
    "    query_preproc_fn=lambda query: f\"query: {query}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e3053f4-72af-4020-877a-7d2d0873cd90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a258442e4dd40d5b50d79f2b90b44fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scoring queries:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hits_1': 0.74,\n",
       " 'hits_5': 0.94,\n",
       " 'hits_10': 0.97,\n",
       " 'dcg_5': 0.8478792682167118,\n",
       " 'dcg_10': 0.8576362683546332,\n",
       " 'dcg_20': 0.8616240208821239,\n",
       " 'time_per_query': 0.032037713527679444,\n",
       " 'not_found_queries': [{'doc_id': 42,\n",
       "   'doc_title': 'Огнеупоры. Буквенные обозначения величин, применяемых при испытаниях',\n",
       "   'query': 'исо стандарты огнеупоры'},\n",
       "  {'doc_id': 1258,\n",
       "   'doc_title': 'Аппараты пускорегулирующие для разрядных ламп. Общие технические требования',\n",
       "   'query': 'тест-таблицы для факсимильных аппаратов'},\n",
       "  {'doc_id': 2211,\n",
       "   'doc_title': 'Тара транспортная наполненная. Метод испытания в водяных брызгах',\n",
       "   'query': 'защита товара от дождя гост'}]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectorstore_pipeline( # e5-large\n",
    "    faiss_vectorstore_titles,\n",
    "    queries,\n",
    "    hits_ks=[1, 5, 10],\n",
    "    dcg_ks=[5, 10, 20],\n",
    "    not_found_queries_threshold=20,\n",
    "    progress_bar=True,\n",
    "    query_preproc_fn=lambda query: f\"query: {query}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e2c8fc89-1012-45f2-ba91-451bcc9731d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bab3b5521574c4d926cdb9003e5ad67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scoring queries:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hits_1': 0.71,\n",
       " 'hits_5': 0.935,\n",
       " 'hits_10': 0.985,\n",
       " 'dcg_5': 0.8317361854103221,\n",
       " 'dcg_10': 0.848172067535831,\n",
       " 'dcg_20': 0.8493953202464221,\n",
       " 'time_per_query': 0.07090999364852905,\n",
       " 'not_found_queries': [{'doc_id': 2211,\n",
       "   'doc_title': 'Тара транспортная наполненная. Метод испытания в водяных брызгах',\n",
       "   'query': 'защита товара от дождя гост'},\n",
       "  {'doc_id': 1523,\n",
       "   'doc_title': 'Совместимость технических средств электромагнитная. Радиопомехи индустриальные от устройств с двигателями внутреннего сгорания. Нормы и методы испытаний',\n",
       "   'query': 'методы измерения радиопомех от двс'}]}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectorstore_pipeline( # e5-large only chunks\n",
    "    faiss_vectorstore,\n",
    "    queries,\n",
    "    hits_ks=[1, 5, 10],\n",
    "    dcg_ks=[5, 10, 20],\n",
    "    not_found_queries_threshold=20,\n",
    "    progress_bar=True,\n",
    "    query_preproc_fn=lambda query: f\"query: {query}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38df57cd-b891-49b2-bc3e-55b0e55d8b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "\n",
    "client = QdrantClient(host=\"localhost\", port=6333)\n",
    "\n",
    "collection_name = \"gosts\"\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=1024,\n",
    "        distance=models.Distance.COSINE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de6d6386-b0e0-46e8-9679-882b7cbfcd7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ffb46a52b2479b93b3c7259ab9017a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(all_docs):\n",
    "    client.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=[\n",
    "            models.PointStruct(\n",
    "                id=doc['id'],\n",
    "                vector=doc['embedding_title'],\n",
    "                payload={\n",
    "                    \"text\": doc['text'],\n",
    "                    'metadata': {\n",
    "                        \"title\": doc['title']\n",
    "                    }\n",
    "                    \n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2e61e7f-5498-4a76-9396-90c0e54c136e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_vectorstore = Qdrant(client, collection_name, hf, content_payload_key='text', metadata_payload_key='metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b5fc023-dec7-4ace-a49c-f1f945b48365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ed7ff458b6042ceae3d519abb4622f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scoring queries:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hits_1': 0.725,\n",
       " 'hits_5': 0.94,\n",
       " 'hits_10': 0.97,\n",
       " 'dcg_5': 0.8423432145202834,\n",
       " 'dcg_10': 0.8521002146582051,\n",
       " 'dcg_20': 0.8560879671856957,\n",
       " 'time_per_query': 0.08718831777572632,\n",
       " 'not_found_queries': [{'doc_id': 42,\n",
       "   'doc_title': 'Огнеупоры. Буквенные обозначения величин, применяемых при испытаниях',\n",
       "   'query': 'исо стандарты огнеупоры'},\n",
       "  {'doc_id': 1258,\n",
       "   'doc_title': 'Аппараты пускорегулирующие для разрядных ламп. Общие технические требования',\n",
       "   'query': 'тест-таблицы для факсимильных аппаратов'},\n",
       "  {'doc_id': 2211,\n",
       "   'doc_title': 'Тара транспортная наполненная. Метод испытания в водяных брызгах',\n",
       "   'query': 'защита товара от дождя гост'}]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectorstore_pipeline(\n",
    "    qdrant_vectorstore,\n",
    "    queries,\n",
    "    hits_ks=[1, 5, 10],\n",
    "    dcg_ks=[5, 10, 20],\n",
    "    not_found_queries_threshold=20,\n",
    "    progress_bar=True,\n",
    "    query_preproc_fn=lambda query: f\"query: {query}\",\n",
    "    doc_id_str='_id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8324ba5-4481-4e9f-b55b-5011e8c99f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bm25 clear:\n",
      "HITS@1: 0.395\n",
      "HITS@5: 0.655\n",
      "HITS@10: 0.72\n",
      "DCG@5: 0.53\n",
      "DCG@10: 0.55\n",
      "DCG@20: 0.571\n",
      "Average time per query: 10.4ms\n",
      "Number of not found queries: 40\n",
      "\n",
      "Bm25 stemmed:\n",
      "HITS@1: 0.56\n",
      "HITS@5: 0.83\n",
      "HITS@10: 0.895\n",
      "DCG@5: 0.709\n",
      "DCG@10: 0.73\n",
      "DCG@20: 0.74\n",
      "Average time per query: 10.0ms\n",
      "Number of not found queries: 13\n",
      "\n",
      "Bm25 lemmatized:\n",
      "HITS@1: 0.57\n",
      "HITS@5: 0.82\n",
      "HITS@10: 0.9\n",
      "DCG@5: 0.707\n",
      "DCG@10: 0.732\n",
      "DCG@20: 0.741\n",
      "Average time per query: 1952.6ms\n",
      "Number of not found queries: 13\n",
      "\n",
      "Tfidf lemmatized:\n",
      "HITS@1: 0.42\n",
      "HITS@5: 0.775\n",
      "HITS@10: 0.875\n",
      "DCG@5: 0.616\n",
      "DCG@10: 0.647\n",
      "DCG@20: 0.66\n",
      "Average time per query: 12756.1ms\n",
      "Number of not found queries: 15\n",
      "\n",
      "Tfidf clear:\n",
      "HITS@1: 0.41\n",
      "HITS@5: 0.74\n",
      "HITS@10: 0.83\n",
      "DCG@5: 0.586\n",
      "DCG@10: 0.615\n",
      "DCG@20: 0.626\n",
      "Average time per query: 7514.4ms\n",
      "Number of not found queries: 26\n",
      "\n",
      "Tfidf stemmed:\n",
      "HITS@1: 0.445\n",
      "HITS@5: 0.775\n",
      "HITS@10: 0.9\n",
      "DCG@5: 0.63\n",
      "DCG@10: 0.67\n",
      "DCG@20: 0.681\n",
      "Average time per query: 7095.6ms\n",
      "Number of not found queries: 11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretty_print_results(results, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0f621d-4969-44ac-980b-3d6e7913bb22",
   "metadata": {},
   "source": [
    "## other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8429c4bc-f9f1-4427-9c74-4e47e5bad7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/results.pickle', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "15b662c4-c404-4247-8078-74e38740b44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc_id': 2414,\n",
       " 'filename': 'gost_30422-96.pdf',\n",
       " 'doc_gost_number': 'ГОСТ 30422-96',\n",
       " 'doc_title': 'Табак и табачные изделия. Сигареты. Определение скорости свободного горения',\n",
       " 'queries': ['скорость сигаретного горения', 'определение горения сигареты']}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 0\n",
    "queries[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9992c1e2-9f28-4c2a-853c-5f0c2b4fc819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'doc_id': 2414,\n",
       "  'title': 'Табак и табачные изделия. Сигареты. Определение скорости свободного горения'},\n",
       " {'doc_id': 2410, 'title': 'Сигареты. Отбор проб'},\n",
       " {'doc_id': 2415, 'title': 'Сигареты. Определение степени осыпаемости'},\n",
       " {'doc_id': 2411, 'title': 'Сигареты. Отбор проб'},\n",
       " {'doc_id': 2413,\n",
       "  'title': 'Сигареты и фильтры. Определение номинального диаметра. Пневматический метод'},\n",
       " {'doc_id': 1175,\n",
       "  'title': 'Материалы электроизоляционные твердые. Метод определения стойкости к действию электрической дуги постоянного тока низкого напряжения'},\n",
       " {'doc_id': 478,\n",
       "  'title': 'Система стандартов безопасности труда. Пожаровзрывоопасность веществ и материалов. Номенклатура показателей и методы их определения'},\n",
       " {'doc_id': 1174,\n",
       "  'title': 'Материалы электроизоляционные твердые. Метод определения стойкости к действию электрической дуги малого тока высокого напряжения'},\n",
       " {'doc_id': 476,\n",
       "  'title': 'Система стандартов безопасности труда. Пожаровзрывоопасность веществ и материалов. Номенклатура показателей и методы их определения'},\n",
       " {'doc_id': 3310,\n",
       "  'title': 'Дороги автомобильные общего пользования. Тоннели. Требования к проектированию системы вентиляции'},\n",
       " {'doc_id': 1790,\n",
       "  'title': 'Материалы неметаллические для отделки интерьера автотранспортных средств. Метод определения огнеопасности'},\n",
       " {'doc_id': 477,\n",
       "  'title': 'Система стандартов безопасности труда. Пожаровзрывоопасность веществ и материалов. Номенклатура показателей и методы их определения'},\n",
       " {'doc_id': 3028,\n",
       "  'title': 'Пластмассы конструкционные. Номенклатура показателей'},\n",
       " {'doc_id': 473,\n",
       "  'title': 'Система стандартов безопасности труда. Пожарная безопасность. Общие требования'},\n",
       " {'doc_id': 17,\n",
       "  'title': 'Система стандартов безопасности труда. Пожарная безопасность. Термины и определения'},\n",
       " {'doc_id': 3415,\n",
       "  'title': 'Оборудование промышленное газоиспользующее. Воздухонагреватели. Общие технические требования'},\n",
       " {'doc_id': 3006,\n",
       "  'title': 'Пластмассы. Метод определения поведения пластмасс при контакте с раскаленным стержнем'},\n",
       " {'doc_id': 1261,\n",
       "  'title': 'Лампы электрические. Методы измерения электрических и световых параметров'},\n",
       " {'doc_id': 1053,\n",
       "  'title': 'Горелки газовые промышленные. Общие технические требования'},\n",
       " {'doc_id': 18,\n",
       "  'title': 'Система стандартов безопасности труда. Пожарная техника. Термины и определения'}]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = retriever.invoke(queries[k]['queries'][1])\n",
    "[res.metadata for res in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20f81f5-9ee9-44de-ba8a-3da52ecece2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
